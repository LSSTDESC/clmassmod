\documentclass[11pt]{article}

\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{ifthen}
\usepackage[all]{hypcap}
\newcommand{\logfig}[2]{
See figure~\ref{fig:#1}.
\begin{figure}[!ht] 
\includegraphics[width=0.8\textwidth]{#1} 
\caption{#2} 
\label{fig:#1} 
\end{figure}
}

\bibliographystyle{aa_arxiv}

\def\aj{AJ}%
          % Astronomical Journal
\def\araa{ARA\&A}%
          % Annual Review of Astron and Astrophys
\def\apj{ApJ}%
          % Astrophysical Journal
\def\apjl{ApJ}%
          % Astrophysical Journal, Letters
\def\apjs{ApJS}%
          % Astrophysical Journal, Supplement
\def\aap{A\&A}%
          % Astronomy and Astrophysics
\def\aapr{A\&A~Rev.}%
          % Astronomy and Astrophysics Reviews
\def\aaps{A\&AS}%
          % Astronomy and Astrophysics, Supplement
\def\jcap{JCAP}%
          %Journal of Cosmology and Astroparticle Physics
\def\mnras{MNRAS}%
          % Monthly Notices of the RAS
\def\nat{Nature}%
          % Nature
\def\pasj{PASJ}%
          % Publications of the Astronomical Society of Japan
\def\pasp{PASP}%
          % Publications of the ASP
\def\physrep{Phys.~Rep.}%
          % Physics Reports
\def\prd{Phys.~Rev.~D}
          % Physical Review D
\let\apjlett=\apjl


\title{Analysis Document: Weak Lensing Calibration with N-body Simulations}
\date{Started ~Feb 2013}
\author{Douglas Applegate}


\begin{document}

\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Project Description}

The goal of this project is to measure and improve the systematic uncertainty from mass-profile modeling in weak lensing. In the Weighing the Giants analysis, we assumed an NFW density profile. Does that bias the mean mass of the sample? How well can we constrain that bias? Starting at that point, I am to answer some of the following questions:

\begin{itemize}
\item What is the bias when you fit an NFW halo? What is the optimal radial range to fit, in terms of bias, systematic uncertainty and statistical uncertainty?
\item Is the NFW profile the best description? Do other profiles work better? Are there other ways to measure masses (eg Mass Aperture) that are better?
\item How does this evolve with cluster mass, and with redshift? Are there other predictors?
\item How do we best handle the mass-concentration relation?
\item How do we best handle the prior on cluster mass?
\item Are there differences in predictions from different simulations, and from different ways to simulate lensing?
\end{itemize}

The simulations may also give insights into more advanced topics, such as 
\begin{itemize}
\item What can simulations tell us about applying contamination corrections?
\item Can we measure cluster concentrations?
\item Can we measure cluster ellipticities, and over what radial range?
\item If designing a survey from scratch, how should we do it?
\end{itemize}

There are currently three analysis efforts that these results feed into. The first is the Stanford Weighing the Giants work, with Steve, Adam, and Anja, working with wide field, ground-based observations from Subaru. Then there is the SPT efforts at low and high redshifts, with Tim and Joerg. The high-z work uses HST observations, whereas the low-z work uses Megacam @ Magellan. Finally, this work also feeds into the LSST effort.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage


\section{Log}

\paragraph{15 July 2013}
Lots of development work during the March period that was undocumented. 
Basically, got running on Becker's simulations. 
Oddly, though, I couldn't reproduce his results. 
Not sure why, but it may be because I am only looking at the most massive halos while he was fitting biases to all halos.
While there are many things that I can do to try to recover Matt's results, I don't know if I can.
First step is to go back to my results, and just figure out what is going on.


\paragraph{01 Jan 2013}
Start of this work package. 
First step is to clean up old code that I've been using in bonnpipeline and get it running with Will's simulated catalogs.

\paragraph{06 Aug 2013}
I've recieved from Jiayi in Munich a distribution of SZ - halo center offsets from a new set of hydro sims they've done. I'm going to explore the offset distributions and effects on an NFW halo in an ipython notebook called: simulated\_offsets.ipynb .

\paragraph{19 Feb 2014}
After a long gap in this notebook, I'm back to updating it and tracking my research investigations. Since I've last updated, I've added two new simulation sets, the BCC and the MXXL. I've implemented a uniform analysis, and have begun exploring different radial ranges, as well as differences between the two simulations. I've updated all sections of the notebook to try to capture these pieces.

\paragraph{21 Feb 2014}
Setting up simulations for two different experiments: understanding the noise and bias tradeoffs for the HST simulations, and understanding the effect of decreased sampling density and increased shape noise. Added configuration files, and utilities to generate configuration files. Modifications to nfwfit and associated software to deal with subsampling, shifting to different redshifts, and adding shape noise.

\paragraph{24 Feb 2014}
Looking at results from changing noise \& sampling density in MXXL and BCC. See section~\ref{sec:noisebias}.
Also looking at predictions for noise and bias for proposed HST snapshot programs. See section~\ref{sec:hstproposal}.

\paragraph{25 Feb 2014}
Looked at the results for the HST mock-ups. There was a bug, in that I forgot to change the area accepted when I pretend clusters are at different redshifts. Rerunning that.

\paragraph{26 Feb 2014}
While I'm rerunning the HST stuff, I wanted to look at the posterior of a few individual clusters. See section~\ref{sec:noisebias_posteriors}.

\paragraph{27 Feb 2014}
Starting to set up a few more explorations: binning \& cosmology-dependent mass-concentration relation.

\paragraph{28 Feb 2014}
Attempting to catch up on my notes from this last week. Need to add info on noise effects(sec~\ref{sec:noisebias}) and the hst proposal (sec~\ref{sec:hstproposal}).


\paragraph{03 April 2014}
Needed to figure out if I could get away with 3 or 4 pointings with PISCO. PISCo has a 6x8 arcminute field of view, so rather restricted. I worked out a 3 pointing and 2 fourpointing strategies. Looks like I need 4 pointings See sec~\ref{sec:piscoproposal}.

\paragraph{04 April 2014}
Spend the afternoon thinking about what to do with the complex dependences on the bias. See sec~\ref{sec:outerfitrange} for thoughts and plans, and results.

\paragraph{10 April 2014}
Trying to play catch up, and think about the simulations again. I ran some tests on how bining affects results. See sec~\ref{sec:binningmethod}.
Also started to implement a cosmology dependent m-c relation. See sec~\ref{sec:cosmo_dependent_mc}.

\paragraph{9 July 2014}
Fell off the bandwagon again. Updates on what's going on in the BCC in section~\ref{sec:bcc_smoothing}.
Updates on comparing three sets of sims in section~\ref{sec:consistancy}.

\paragraph{5 Nov 2014}
Haven't worked on the simulation effort in quite a long time. Time to pick up the pieces again. The interim period was spent trying to get my collaborators to get me info on the simulations: Matt Becker owes me updated BCC simulations that aren't overly smoothed, Stephen Hilbert owes me mass profiles for MXXL, and Salman Habib owes me any simulations. The immediate task is to figure out how to get an answer for Joerg's and Tim's papers, pronto. What do they need, and how to supply it? Thoughts and musing in sec~\ref{sec:spt_immediateneeds}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage


\section{Guide to Files \& Software}

TODO: Fill in guide to software



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage


\section{Available Simulations}

I have access to 3 sets of simulations:

\paragraph{BK11} : Cut-outs around massive halos at redshifts z=0.25 and z=0.5, used in Becker \& Kravtsov 2011. Particles are extracted in a 20x20x400 comoving Mpc/h box around each cluster and are projected to form a 2-D mass map. From that, a shear signal is calculated, assuming sources are at z=1

\paragraph{BCC} : A simulation of a large sky-area survey covering a continuous patch of sky. Three boxes of decreasing resolution are appended and are used to form a past light cone of the visible universe. The simulation ray-traces shear from each galaxy in the simulation to the observer at z=0. I have extracted galaxies centered around the lensed central position of each massive halo in the simulation. From Wechsler, Becker, and Buscha, priv comm.

\paragraph{MXXL}: A large box where snapshots at particular redshifts are written to disk. I currently have only the z=1 snapshot. Sources are assumed to be at infinite distance (not infinite redshift). Shear is calculated by projecting masses to a plane in a box (of unknown size) around each massive cluster. I have 3 projections for each cluster.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage


\section{Are the simulations consistent?}

In the most basic test, do I recover the same bias as a function of mass from each simulation? There are a few reasons why I might not. 

\begin{itemize}
\item Each simulation probes a different redshift range, so I should be able to probe redshift evolution. Thankfully, the BCC bridges between the MXXL and BK11, while I will also hopefully receive additional snapshots from the MXXL. 
\item Each simulation uses a slightly different cosmology. That may mean that the mass-concentration relations are different, which may again lead to different biases. 
\item Each simulation is at different resolutions, so there could be resolution issues, especially near the cluster centers. 
\item The BCC ray traces over a past light cone, whereas BK11 and the MXXL ignore LSS evolution and don't ray trace
\item The density of points where the shear field is measured is different. Bahe+2012 shows that lower density surveys / noisier surveys average over / miss some substructure, leading to different bias results.
\item There may be a bug in how I'm reading in one of the simulations. This was previously a problem with the BK11 simulations, where I first missed factors of h, and then there was ambiguity about at what redshift the lensing signal was calculated for.
\end{itemize}

\subsection{Basic Analysis Approach}

TODO: Fill in details here on how exactly I do my fits.

The fit is encoded in nfwfit.py. 


\subsection{Smoothing in the BCC}
\label{sec:bcc_smoothing}

\logfig{figures/shearprofilecomp.png}{A comparison of stacked shear profiles in each of the simulations. Data points show the stacked shear profiles, while dotted lines show the predicted NFW for the average mass and average concentration of the sample. (Note that the best comparison model is not $<M>$ and $<c>$.) Notice how the BCC simulations roll over towards zero shear at low radius. This is apparently a smoothing effect, and renders the BCC profiles inaccurate inside 750kpc.}

As of this time (May 2014), I cannot use BCC as a reliable indicator of bias for profiles probing ranges inside 750kpc.
Matt Becker should be working on a solution to this.


\subsection{Comparing Mass Bias vs Radial Range \& M-C Relation}
\label{sec:consistant_bias_mcrelation}

I've run mass fits with three mass-concentration relations: c=4, the Duffy08 relation, and allowing c to be fit freely.

I've run fits for 15 different radial ranges: 3 Inner radii {0.25, 0.5, 0.75 Mpc}, and 6 outer radii {0.5, 0.75, 1.0, 1.5, 2.5, 3.0}. The radial ranges are encoded as follows:

\begin{itemize}
\item 'r1' : '0.25 - 0.5 Mpc',
\item 'r2' : '0.25 - 1.5 Mpc',
\item 'r3' : '0.25 - 2.5 Mpc',
\item 'r4' : '0.25 - 3.0 Mpc',
\item 'r5' : '0.50 - 1.5 Mpc',
\item 'r6' : '0.50 - 2.5 Mpc',
\item 'r7' : '0.50 - 3.0 Mpc',
\item 'r8' : '0.75 - 1.5 Mpc',
\item 'r9' : '0.75 - 2.5 Mpc',
\item 'r10' :'0.75 - 3.0 Mpc',
\item 'r11' :'0.25 - 0.75 Mpc',
\item 'r12' :'0.25 - 1.0 Mpc',
\item 'r13' :'0.50 - 0.75 Mpc',
\item 'r14' :'0.50 - 1.0 Mpc',
\item 'r15' :'0.75 - 1.0 Mpc'
\end{itemize}


When I assume either c=4 or Duffy08, I see that the simulations produce different results. The slopes of bias vs mass change, as well as the absolute normalizations. The three simulations appear to respond differently as well. See figure~\ref{fig:comparing_r7_bias}. The curves seem to shift some between simulations. But since I am refitting the same halos, I would expect that the shifts in each simulation are real. Only when I go to cfree are the BCC and MXXL seemingly consistent. BK11 is hanging out by itself for some reason, which I don't understand.

\begin{figure} \centering[!ht]
\includegraphics[width=0.3\textwidth]{figures/c4_r7}
\includegraphics[width=0.3\textwidth]{figures/duffy_r7}
\includegraphics[width=0.3\textwidth]{figures/cfree_r7}
\caption{Plot of bias versus mass. Left: Assuming c=4, Center: Assuming Duffy08, and Right: C is a free parameter. The fit range is 0.5 - 3.0 Mpc. The width of each colored band represents the $1\sigma$ uncertainty in the median bias for each mass bin. Bins are adaptively created to balance signal-to-noise with exploring the mass range. Note from sec~\ref{sec:bcc_smothing}, I don't expect the BCC lines to be accurate here. Made with compareDiffSims.py}
\label{fig:comparing_r7_bias}
\end{figure}

The agreement between BCC and MXXL seems to be fit range dependent. The above fits covered a range of 0.5 - 3.0 Mpc. If we only look at the outer region for cfree, the fits are again good.

\logfig{figures/cfree_r10}{Same as fig~\ref{fig:comparing_r7_bias}, except now only for cfree and 0.75-3Mpc.}

However, if we look at the innermost fit region, 0.25-0.5 mpc, we can see that the two simulations are drastically different. BCC and BK11 show diving calibrations at the high mass end (0.2 for $10^{15}$ halos!?), but MXXL holds relatively steady up to the highest masses. 

\logfig{figures/cfree_r1}{Same as fig~\ref{fig:figures/cfree_r10}, except for on a radically different scale.}

This is apparently a resolution effect (see sec~\ref{sec:bcc_smoothing}. 


\subsection{Role of Mass-Concentration Relation}

I think that the behavior of the fits against the different mass-concentration relations vs cfree suggests that the simulations have intrinsically different m-c relations. This is supported by the work of \citet{ludlow_mc}, which shows that even for $M_{200} = 10^{14}$ clusters, the mean concentration can vary by 20\% over the WMAP1-7 and Planck cosmologies. 

This to me suggests a 2-pronged strategy. When we don't care about cosmology, for example, just talking about masses, then we can fix a mass-concentration relation (appropriate for that cosmology). However, for purposes of cosmological fits, we need to vary the m-c relation systematically over all clusters inline with the fit. That way we don't get hit by some ``systematic uncertainty'' by assuming an M-C relation, and we capture the covariance with cosmology.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Testing a Cosmology-Dependent Mass-Concentration Relation}
\label{sec:cosmo_dependent_mc}

On Becker's suggestion, I tried out the Zhao08 model for cosmology dependent m-c relations, from \citet{zhao_cosmodepmc}, since they provide an online calculator and code. A calculator is at: \url{http://202.127.29.4/dhzhao/mandc.html}. In short, this more complicated M-C relation did not bring agreement as well as I had hoped.

\begin{figure} \centering
\includegraphics[width=0.4\textwidth]{figures/zhaomc_z25.png}
\includegraphics[width=0.4\textwidth]{figures/zhaomc_z10.png}
\caption{Median bias measured from the BCC, MXXL, and BK11 simulations using the Zhao M-C relation at left: $z=0.25$ and right: $z\approx 1.0$. Agreement is not disheartening, but is not signficiantly improved, either.}
\label{fig:zhamoc}

\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Agreement Between Simulations with Free Concentration}
\label{sec:consistancy}

\begin{figure} \centering
\includegraphics[width=0.6\textwidth]{figures/cfree_z25.png} \\
\includegraphics[width=0.6\textwidth]{figures/cfree_z5.png} \\
\includegraphics[width=0.6\textwidth]{figures/cfree_z10.png}
\caption{Median bias with concentration free, for fit range 750kpc - 3Mpc. Simulations seem to show good agreement.}
\end{figure}

So at least where we expect the simulations to agree, their median bias seems to agree. 
That's positive.
However, why is BK11 mildly higher than BCC and MXXL?


\begin{figure}\centering
  \includegraphics[width=0.4\textwidth]{figures/lowz_logscatter.png}
  \includegraphics[width=0.4\textwidth]{figures/lowz_logscatter_cdf.png}
\caption{Scatter in recovered masses versus true masses. First, the scatter in the BCC is much larger since only that simulation measures the full LoS noise. Second, MXXL and BK11 seem to agree in their distribution at the low scatter, but the BK11 has slightly more up scatter. A KS test says that this is significant at $p=0.0024$, for $D=0.081$. However, maybe this is just the fact that BK11 has twice the LoS integration as MXXL? }
\end{figure}

This points towards a possibly scary conclusion. Can we not know the bias without folding in the full LoS scatter? But...the BCC settles back to the MXXL value! So maybe its not so bad anyway? Or is there something different about the LoS scatter in BK11?

Also, what causes the tail to high overestimates? This was seen and clearly measured by Matt in BK11. But he doesn't discuss a cause.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Next Tasks}

\begin{itemize}
\item Inspect clusters that are in the highly skewed tail. Is there anything characteristic about their shear profiles?
\item Download and analysize BK11 simulations with only 200Mpc integration length. Is the scatter distribution consistant with the MXXL?
\item Can I recover the scatter in Bk11 and BCC by convolving the measured MXXL scatter with an appropriate function?
\end{itemize}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage



\section{Optimal Radial Ranges for NFW Profiles}

Question: What is the best radial range to use when fitting an NFW profile? I need to provide answers in two different regiemes, which in the end may end up overlapping. The first is the SPT regime, where the limited field of view on Hubble restricts how far out we can probe. The second regime is ground-based wide-field data from Subaru or LSST, where we can go out as far as we want.

I ran 15 different fit ranges (see~\ref{sec:consistant_bias_mcrelation}) for all 3 simulations. Right now I am biased towards MXXL, so I will only show results for that at the moment.

\logfig{figures/cfree}{Plotting mass bias from lensing versus cluster mass, using the MXXL simulation and no m-c relation, for different radial ranges. Line styles denote different inner fit boundaries, while color denotes different outer fit boundaries. Color are grouped, suggesting that the outer fit boundary is more important than the inner fit boundary. Produced with compareSims.py}

Outer fit range seems to matter much more than inner fit range. You might expect that the behavior changes as the fit includes or excludes r200. R200 is at ~1.1Mpc for $10^{14.5}$ clusters, whereas it is closer to 1.4Mpc for $10^{15}$ clusters. So for example, fitting out to 1Mpc is inside R200 for all clusters, and that bias seems to stay pretty level for all masses (the last bin is noisy). The pink line, fitting to 1.5mpc, is somewhat outside R200 for the lighter clusters, and just barely outside for the most massive -- that line shows larger cluster masses at higher true masses. If for some reason fitting m\&c biases masses up, then the pink line could be converging to the ``right'' answer at higher masses. Similar story for 2.5 and 3 Mpc, where masses are notably underestimated at low masses, and the trend heads to less bias at higher masses. I'm not sure how to explain the green lines, fitting to only 750kpc. 


\textbf{Could I fit perfect NFW halos and add noise? That way I could see the effects of noise bias on a two parameter fit?}


\logfig{figures/cfree_scatter}{Plotting intrinsic scatter versus mass for different radial ranges, using the MXXL simulation and no m-c relation. Same coloring and line scheme as fig.~\ref{fig:figures/cfree}. Scatter increases as I limit the outer radius used in the fit.}

The story with the scatter is much clearer. As I move the outer radial range to small values, the amount of scatter picks up. As soon as I move inside R200, the scatter blows up. Why is this? Smaller area, so subject to more LSS noise? More substructure in clusters?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Dealing with the Outer Fit Range}
\label{sec:outerfitrange}

Looking at figures \ref{fig:figures/cfree} and \ref{fig:figures/cfree_scatter}, the outer fit range seems to control the bias. And for each choice, there is a different mass dependence, probably described by how $R_{\mathrm{vir}}$ passes through the fit range for the masses I'm considering. It seems silly that the bias is this sensitive to the fit range, when in many cases the fit range isn't even something that I can control.

This bias comes from the fact that an NFW halo is a bad description of a cluster at distances beyond the virial radius. The NFW halo cuts off, and eventually a 2-halo term kicks in. Becker points this out in Fig 2 of his paper \citep{becker11}, and it goes along with other work by \citet{oguri_profiles} and \citet{tavio_profiles}, both of which propose suggested functional forms to model the density profile beyond the virial radius. Figure~4 in \citet{tavio_profiles} is particularly interesting, because he plots the rms scatter in the density profile as a function of radius. Above the virial radius, the rms scatter explodes from 20\% to 100\% by 2*$R_{\mathrm{vir}}$. Regardless of the functional form, this translates into a huge uncertainty in the shear profile of an individual cluster. So imagine if we included that theoretical uncertainty when fitting clusters? The fit would basically ignore any data above the virial radius, while self consistantly calculating the virial radius. That's exactly what the iterative method in \citet{becker11} tried to do, but without the iteration.

I've tried implimenting this in code. At r200, I started ramping up the uncertainty, and made the uncertainty really large outside r200. The result? The fitter removed all mass from the halo, so that all the measured signal was outside r200. That of course squashes chisquared. Messing around with masses versus r200 radii, I just don't think this will work. For any mass less than 1e14, r200 is barely inside 750kpc, especially at higher redshifts. I could make the prior tighter, but then I can't properly catch how the uncertainty tails to low mass.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Next Steps}

For the HST proposal (due to STSCI in April, but need it for proposal writing by 25 Feb 2014), I need to add shape noise, use a lower sampling density, and apply HST masks associated with our mosaicing programs. That way I can directly measure the expected scatter for different choices, which will affect how powerful the HST program will be. 

There are some more general steps that I would like to do as well:
\begin{itemize}
\item Noise. I want to understand how the 2-parameter fit responds to noise. I could create perfect NFW halos and add shape noise to see how the best fit value changes. I also want to explore the 2D posterior surface for some of the clusters in MXXL, both relaxed and unrelaxed. Related, how does the posterior perform when I marginalize over it instead of using a point estimator?
\item We may in the end use a 1-parameter fit, but since the M-C relation is cosmology dependent, I need to implement a cosmology dependent relation. How does that perform?
\item Does the bias simplify if I add a ton of extra uncertainty at radii beyond the virial radius?
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage

\section{What are the effects of noise and sampling density on bias \& scatter?}
\label{sec:noisebias}

\subsection{Motivation}
I'm doing nonlinear fits to noisy data, and taking point estimates of the posterior. We generally expect that doing that will produce biased results. It may also explain the differences between BCC, MXXL and BK11 simulations. While all three simulations are noise-free, shear fields are sampled at different densities, which may have an effect.

\subsection{Set up}

I have submitted runs on the MXXL and BCC with different densities. All of the following are galaxies(samples) per square arcminute.
\begin{itemize}
\item 0: Default density
\item 1: 100 (MXXL only)
\item 2: 20 (MXXL only)
\item 3: 20
\item 4: 7
\item 5: 4  (MXXL only)
\item 6: 1  (MXXL only)
\end{itemize}

I have used four different noise levels.
\begin{itemize}
\item 0: No noise
\item 1: 0.16 shape noise on tangential shear
\item 2: 0.33
\item 3: 0.5
\end{itemize}

I ran with c4 and cfree MC relations using the standard nfwfit.py software. Comparisons were made using the script compareSampling.py, and with the logfile compareSampling.log.


%%%%%%%%

\subsection{Does MXXL and BCC agree when using the same sampling density?}

We already know that the two simulations don't agree if c=4, so I will skip that.


\begin{figure} \centering
\includegraphics[width=0.3\textwidth]{figures/density_cfree-r1}
\includegraphics[width=0.3\textwidth]{figures/density_cfree-r5}
\includegraphics[width=0.3\textwidth]{figures/density_cfree-r10}
\caption{Bias measured from the BCC and MXXL simulations. No shape noise is added, but different sampling densities are used. Left, center, and right are using three different fit radii.}
\label{fig:bcc_vs_mxxl_density}
\end{figure}

We can see the bias comparison in figure~\ref{fig:bcc_vs_mxxl_density}. The center and right panels, fitting and 0.5Mpc and above, show a clean story. I would argue that the simulations roughly agree in the mass range where they have overlapping statistics. The correspondance breaks down a bit in the center panel, but again, rough agreement. In the left panel, we can see that density is really important. With enough sample points, the bias is well behaved (solid red and green curves). But sample sparsely, and the bias jumps up. But the two simulations roughly agree.

\begin{figure} \centering
\includegraphics[width=0.4\textwidth]{figures/density_cfree-r5_scatter}
\includegraphics[width=0.4\textwidth]{figures/density_cfree-r10_scatter}
\caption{Comparison of recovered scatters from the two simulations.}
\label{fig:bcc_vs_mxxl_density_scatter}
\end{figure}

When it comes to the scatter, however, the two simulations do not agree. From figure~\ref{fig:bcc_vs_mxxl_density_scatter}, we see that the MXXL has a scatter of ~20\%, practically independent of sampling density. The BCC has a scatter of 30-40\%, with signs of mass dependence. Again, density does not appear to matter. 

\textbf{Why does the scatter not change as the sampling density is reduced (until very low density)?}
10x more noise, when the noise is non-existant, is still non-existant noise, no?

\subsubsection{Redshift evolution in BCC bias}

I broke down the BCC bias and scatter as a function of mass and redshiftin figure~\ref{fig:bcc_bias_redshift_evo}. This is only for the outer region. However, we see that there does appear to be evolution in the bias and scatter with redshift \emph{and} mass. However, the evolution in bias is < 10\%. I do not think that is enough to explain the extra scatter.

\begin{figure} \centering
\includegraphics[width=0.8\textwidth]{figures/bcc_bias_redshift_evo_r10_n0_0}
\caption{Evolution of BCC calibration as a function of mass and redshift (colored lines). Left: Bias, Right: Scatter. We do see some redshift evolution(!). It does not appear to be enough to explain the extra scatter in the BCC, but it is important include when trying to calculate the actual bias expected.}
\label{fig:bcc_bias_redshift_evo}
\end{figure}

\subsubsection{Explaining BCC vs MXXL scatter differences with integration length}

Turns out Becker already thought about this in \citet{becker11}. MXXL only includes structure out to 200 Mpc $h^{-1}$, as did BK11. That captures all of the correlated scatter, and some but not all of the uncorrelated scatter. Becker used the calculation from \citet{hoekstra2003} to estimate how much extra noise comes from the rest of the LOS structure. For the lower-mass clusters in BK11 (Section 4.1 and Table 1), the extra LoS noise brings the scatter from $\approx22\%$ to $30\%$. The effect is much smaller for halos $M_{500} > 5\times10^{14}$, where only a few to 5\% points are added to the scatter.



\subsubsection{Sensitivity to Profile Assumptions}

The bias response from assuming an incorrect mass-concentration relation is cosmology dependent \emph{and} radial dependent. In figure~\ref{fig:profile_sensitivity_range_cosmo}, the bias as a function of mass changes with both variables in a way much larger than the difference between different sampling levels.

\begin{figure} \centering
\includegraphics[width=0.4\textwidth]{figures/density_cfree-r5}
\includegraphics[width=0.4\textwidth]{figures/density_cfree-r10}\\
\includegraphics[width=0.4\textwidth]{figures/density_c4-r5}
\includegraphics[width=0.4\textwidth]{figures/density_c4-r10}
\caption{A comparison of how the mass-dependent bias changes with cosmology, radial range, mass-concentration relation, and sampling density. Notice how freeing the concentration radically changes the bias, even for high noise simulations.}
\label{fig:profile_sensitivity_range_cosmo}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{To Consider: If bias depends on cosmology}

I've seen that the two simulations seem to agree when I fit for concentration, at large radii, but that breaks down some at the inner most radii. What if that difference is real, and caused by substructure? What if different cosmologies produce clusters with different amounts of substructure, which lead to different measured biases? 

First, we need to make sure the analysis is robust against substructure and m-c relation. But at some level, \emph{the expected bias has to be cosmology dependent!}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{How does the posterior change as noise is added?}
\label{sec:noisebias_posteriors}

On Monday, I examined how the bias and scatter change as the noise levels change in the simulation. I noticed that the bias tends to increase with increasing noise. I think that is the effect of ``noise bias'', as in the posterior is becoming more skewed at high noise levels. I should be able to see that for individual halos. 

code: inspectProfiles.py
Logfile: logs/noisebias\_probsurface.log

Yeah, this is not working out so well. I think I'll need to table this until later.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{How does the bias \& scatter change as noise is added?}
\label{sec:noisebias_bias}

%%%%

\subsubsection{Scatter at high densities}

I'll start with 100 galaxies per sq arcminute. At the outer radii, this is a lot of samples even for noisy galaxies. The behavior of the scatter, however, has some odd radial dependence. See figure~\ref{fig:noisebias_highdensity_radrange}. The smaller fit range has noise that goes up uniformly. That to me suggests the noise is dominated by shape noise. At the outer radii, there are more galaxies included in the fit, so I guess shape noise is suppressed more. OK, not surprising then that the noise rises slower. However, the scatter develops a mass dependence. From the no noise case, we can see that the intrinsic LSS \& triaxial noise is not mass dependent. So maybe this is a signal strength effect, which gets swamped in the shape-noise dominated case at lower radii?

Note that fitting for concentration increases noise, but not radically, except at low radii.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{figures/noise_cfree-r5-n1_3_scatter}
\includegraphics[width=0.4\textwidth]{figures/noise_cfree-r10-n1_3_scatter}\\
\includegraphics[width=0.4\textwidth]{figures/noise_c4-r5-n1_3_scatter}
\includegraphics[width=0.4\textwidth]{figures/noise_c4-r10-n1_3_scatter}
\caption{Shown are the measured scatters for 100 galaxies per sq arcminute at different levels of noise. Left column shows fits to 0.5-1.5mpc, whereas the right column shows 0.75 - 3mpc. Top row has concentration free in the fits, the bottom row restricts c=4. Fits to 0.5-1.5mpc behave as I would expect: add shape noise, and the measured scatter goes up. However, fits to 0.75-3mpc show a mass dependence to the noise. While noise goes up, it goes up faster for the low mass galaxies, and at a rate slower than the smaller fit range.}
\label{fig:noisebias_highdensity_radrange}
\end{figure}

%%%%%

\subsubsection{Bias at high densities}

As was seen in \citet{bahe12}, added noise shifts the average bias up. However, at least at 100 galaxies per sq arcmin, the effect is not large, and is somewhat muddled. Also confusing is why the c-free fits to 0.5 - 1.5 mpc develops a mass-dependent bias. See Figure~\ref{fig:noisebias_highdensity_bias}.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{figures/noise_cfree-r5-n1_3}
\includegraphics[width=0.4\textwidth]{figures/noise_cfree-r10-n1_3}\\
\includegraphics[width=0.4\textwidth]{figures/noise_c4-r5-n1_3}
\includegraphics[width=0.4\textwidth]{figures/noise_c4-r10-n1_3}
\caption{Same as fig~\ref{fig:noisebias_highdensity_radrange}, except now I show the bias. What is odd is the c-free fit to 0.5-1.5 mpc, and there is a mass-dependent bias. This was seen previously in multiple figures earlier in this section.}
\label{fig:noisebias_highdensity_bias}
\end{figure}

%%%%%%%

\subsubsection{Bias vs sampling for noisy galaxies}

For the most dramatic example of how noise affects the bias, I turn to noisy galaxies, and change the sampling density at 0.75-3mpc. See figure~\ref{fig:noisebias_noisygals_sparsesampling}.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{figures/density_noise2_c4-r10}
\includegraphics[width=0.4\textwidth]{figures/density_noise2_c4-r10_scatter}\\
\includegraphics[width=0.4\textwidth]{figures/density_noise2_cfree-r10}
\includegraphics[width=0.4\textwidth]{figures/density_noise2_cfree-r10_scatter}
\caption{Plotted are simulations with increasing noise levels (fit at 0.75-3mpc). Top has c=4, bottom has c-free. The bias is similar at low noise, and seems to shift in similar ways, though the c=4 fit never shifts bias as much as c-free. Interestingly enough, the scatter does not increase dramatically at this radii when concentration is let free. This is in contrast to smaller radii. Obviously fitting for the concentration has an effect, as it changes the bias, but somehow it doesn't change the scatter.}
\label{fig:noisebias_noisygals_sparsesampling}
\end{figure}

Why does bias seems to increase in a mass independent way up to some noise point, after which lower mass clusters develop a steeper bias? The effects aren't as strong with c=4. But I suspect noise bias is at play here. The direction of the bias would suggest skewed posteriors, with tails to to low mass, and high probability density just above the correct mass. I will have to find a way to see that.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Effects of Binning on Bias \& Scatter}
\label{sec:binningmethod}

When I fit to the innermost region, for example 0.25 Mpc - 0.5Mpc, we see some funky effects going on. Fig~\ref{fig:figures/cfree_r1} shows that MXXL and BCC disagree on the bias, and that BCC is a terribly negative bias in this inner fit range while MXXL does not. When we control for sampling density in Fig~\ref{fig:bcc_vs_mxxl_density}, we see that the MXXL bias moves to match the BCC bias. Could this simply be an artifact of how I bin the profiles? Currently I create radial bins with equal numbers of galaxies. At lower sampling densities, the inner most bin will stretch over a wider and wider radial range. Let us test that.

Using the MXXL, I ran every combination of:

\begin{itemize}
\item MC Relation: c4, cfree
\item Density: Full density, 7 galaxies/arcmin.
\item Radial Range: r11 (0.25 - 0.75), r5 (0.5 - 1.5), r6 (0.5 - 2.5), r10 (0.75 - 3)
\item Binning: Equal50, Equal200, Log6, Log12, Log18, Linear6, Linear12, Linear18
\end{itemize}


First, looking at large radial fits for fixed mass-concentration. Binning method appears to make a difference, however, the change in bias is roughly about 1 percentage-point. That's about half the difference of going from effectively infinite signal to 7 galaxies/arcmin. See fig~\ref{fig:density_binning_bias}. The story seems to be roughly the same for fits to 0.25 - 0.75, at for fits starting at 0.5 Mpc.

Once we let the concentration free, things get slightly more interesting. The fits to 0.75 - 0.3 Mpc still seem to be well behaved, and in fact have a very similar bias to the c=4 fits. Basically, those fits are insensitive to the m-c relation. Fitting with cfree to 0.25 - 0.75 is different. With high source density the bias shifts, but is relatively insensitive to binning (6\% point spread). Once the source density drops to something reasonable, then different profiles just go nuts to different biases. Equal binning sinks to very negative biases, linear and log binning appears to have a positive bias. Can't quite make out a pattern in terms of number of bins.

\begin{figure}
\centering
\includegraphics[width=0.45\textwidth]{figures/density_binning_wtg}
\includegraphics[width=0.45\textwidth]{figures/density_binning_wtg_cfree} \\
\includegraphics[width=0.45\textwidth]{figures/density_binning_core}
\includegraphics[width=0.45\textwidth]{figures/density_binning_core_cfree}\\
\caption{Comparison of bias at different densities and with different binning styles. For fits at high radius, binning style matters less than density. For the core, binning does matter, but at low densities, everything is very sensitive.}
\label{fig:density_binning_bias}
\end{figure}


Binning appears to have no effect on the scatter. Apparently these densities also have no effect on the scatter. 7 galaxies / arcmin must then still be high enough that intrinsic, correlated, and LoS structure is still the dominant noise source, at least for noise free shears.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Next Steps}

I'd like to create perfect NFW halos, increase noise slowly, and inspect the posterior. That is probably the most clean way to investigate the effects of noise bias. However, what I'm concerned about is that the noise due to LSS \& substructure is not the same as shape noise, where noise is actually correlated between bins. I could imagine that correlated noise could induce difference effects. It would also be nice to model the amount of this correlated noise, so that I could include it in fits. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage

\section{What is the best configuration for the HST Program?}
\label{sec:hstproposal}


\subsection{Motivation}
There are a few different ways we could configure an HST program to observe high-redshift galaxy clusters. We can either take a single-pointing strategy, or some sort of mosaic. There are of course time limitions, and mosaicing will usually mean shallower exposures, with higher shape noise and lower galaxy density. The most effective strategy could also be redshift dependent, as the effective beta and sampling densities change.

\subsection{Setup}
I've used the MXXL to examine this question, by employing different instrument masks. I've introduced a few modifications so that I can approximate what happens when galaxy clusters are at different redshifts. This includes different source densities, different physical distances accepted into the analysis, and different effective betas. Modifications include a new reader class, readMXXL\_HSTBeta.py. 

I've used Tim's estimates of Beta, source density, and shape noise from the CANDELS fields. 

From Tim, on 19 Feb. (Note, I clarified that Beta here is $D_{ls}/D_s$, not normalized to $D_inf$.:
\begin{quotation}
Hi Doug,

here are my CANDELS estimates for our new HST program with source density, betas and shape noise:


After color cut ($V-i<0.4$ or $V-z<0.45$) and S/N cuts (Flux $S/N>10$):

Source density: (for V-i cut only so far) 

Single pointings: Ngal= 21/arcmin$^2$ ($24<V<26.5$) to $r=110"$, probably for $z>1$ clusters
[3-pt] Mosaics:          Ngal= 16/arcmin$^2$   ($24<V<26$)   to $r=160"$

Shape noise:
0.40 for both components together

Beta:
zl      beta
0.65  0.43  
0.70  0.40  
0.75  0.38   
0.80  0.36       
0.85  0.34   
0.90  0.32   
0.95  0.30   
1.00  0.28
1.05  0.26
1.10  0.24
1.15  0.23
1.20  0.21 
1.25  0.195
1.30  0.18

This is a bit pessimistic given that it uses uniform and not optimal weight, but this can be seen as margin.

Cheers, Tim
\end{quotation}

I've set up my code to ``move'' clusters to redshifts 0.7, 0.8, 0.9, 1.0, and 1.1. I've also tested single pointings, 3-pt mosiacs, and 4-pt mosaics based on the existing program. I've assumed the source density for the 4-pointing mosaics to be ~21 galaxies per square arcminute.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage


\section{How many pointings do I need with PISCO?}
\label{sec:piscoproposal}


PISCO is a simultaneous imaging system being built at Harvard. It captures griz at the same time, so that each filter is seeing the same colors. This should mean that the colors are more accurate. Problem is, they only put one chip in it, with a field of view of 6x8'. It's kind of hard to probe out to 3Mpc with such a small chip, especially at the redshifts of MACS clusters ($0.3 < z 0.7$).

I came up with 3 different ways I could mosaic. Using 3 pointings, I could probe out along one axis, kind of like -:-. The long axis is 22 arcminutes, but the short one is only 8 arcminutes. With four pointings, I could either form a square that was $14\times14$ arcminutes, with little stubs off two sides. Or, I could make a cross with a hole in the center. Figuring each pointing is offset from the center by 1.5 arcminute, I could probe 1.5 - 9.5 arcminutes.

I set up each of these scenerios, plus a simple circular aperture with diameter 30 arcminute for comparison. While I'm not sure that the absolute scatters recorded are right, I'd think that the relative performance should be right. Figure~\ref{fig:piscoscatter} shows the relative performance. I'm a little surprised the circular aperature does less well at lower masses, but basically the 4 pointing strategy seems to work fine. Three pointings asymptotes to a higher scatter level, which should be avoided.

\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{figures/piscoproposal_scatter}
\caption{Expected Scatter (according to MXXL) as a function of cluster mass, for measuring M200. Four pointing solutions perform better than 3 pointings. Neither 4 pointing solution is a clear winner. Note that at lower masses, the most luxurious solution, the reference circle mask ``subaru'' actually has more scatter. That might be because it allows the profile to be measured all the way to 3Mpc. Could be a useful insight. }
\label{fig:piscoscatter}

\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage

\section{What is the best mass to measure?}

The above work was done looking at M200. However, as it currently stands, we are calibrating masses closer to M500. There is also an open question as to what mass is the least sensitive to m-c assumptions, or put another way, what is the mass that lensing measures the best?

To start, I'd like to remake the above plots with M500 instead of M200. However:

\begin{itemize}
\item The BCC M500 values appear to be larger than the M200 values
\item The MXXL M500 values that I have are for the z=0 slice, not the z=1 slice.
\end{itemize}

I've contacted Aaron about the MXXL problem, but I am holding off contacing Matt about the BCC issue until I am ready to show him some preliminary results.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage

\section{Immediate needs for SPT: Megacam-19 and HST-14}
\label{sec:spt_immediateneeds}

I need to get an answer for Tim and Joerg by the end of November of this month. The problem is still to figure out what exactly do they need from the simulations? How complicated do the predictions need to be?

What makes this hard to answer is that I don't think a constant offset number is going to be sufficient. The masses will be immediately plugged in to a scaling relation code, which will need the detailed relationship between true mass and lensing signal. The prior that will be assumed for the true mass is also going to change.

I think the minimum starting point has got to be measuring $P(g | m_{\mathrm{lens}})$. From that distribution, I can compute any needed summary info (without rerunning the pipeline), and I can apply any prior that I need. The domain for $m_{\mathrm{lens}|}$ has to be as unrestricted as possible, as the possible interpretations and priors will change, ie so that I can test allowing for negative mass, or different mass priors, etc.

That means I should get the mcmc sampling code running. Then I need to adjust the prior and make it improper. From there, I can run on all the simulations that I have, and then look at the posteriors and construct a model that describes all the data. Once I have the sampling from the likelihood, everything else should simply just be a reweighting of those chains.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage \newpage

\section{Collaborators, Acknowledgements, Debts}

\subsection{Collaborators}

Stanford
\begin{itemize}
\item Steve Allen
\item Anja von der Linden
\item Pat Kelly
\item Adam Mantz
\item Glenn Morris
\end{itemize}

Bonn
\begin{itemize}
\item Tim Schrabback
\item Peter Schneider
\end{itemize}

SPT
\begin{itemize}
\item Brad Benson
\item Joerg Dietrich
\end{itemize}

MXXL Simulations
\begin{itemize}
\item Stefan Hilbert
\end{itemize}

BCC Simulations
\begin{itemize}
\item Risa Wechsler
\item Matt Becker
\item Michael Buscha
\end{itemize}

BK11 Simulations
\begin{itemize}
\item Matt Becker
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{refs.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}

